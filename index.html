<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
        content="FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from general 3DGS models to LiDAR. Convert any pretrained 3DGS to a watertight mesh, then perform BVH-accelerated LiDAR ray-casting at 500+ FPS.">
  <meta name="keywords" content="FGGS-LiDAR, 3D Gaussian Splatting, LiDAR simulation, TSDF, BVH, Ray Casting">
  <title>FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <style>
    img.figure {
      width: 100%;
      height: auto;
      border-radius: 12px;
      display: block;
      margin: 0 auto;
      box-shadow: none;
    }
    video.demo {
      width: 100%;
      max-height: 520px;
      border-radius: 12px;
      display: block;
      margin: 0 auto;
      box-shadow: none;
    }
    .box {
      border: none !important;
      box-shadow: none !important;
      background: transparent !important;
      padding: 0 !important;
      margin-top: 2.5rem;
      margin-bottom: 2.5rem;
    }
    p.explain {
      margin-top: 12px;
      text-align: justify;
      font-size: 1rem;
      line-height: 1.6;
    }
    h3.title { margin-bottom: 1rem; }
    section.section { padding-top: 3rem; padding-bottom: 3rem; }
    footer.footer p { color: #555; }
    img.figure:hover { transform: scale(1.01); transition: transform 0.25s ease-in-out; }
  </style>
</head>

<body>

<!-- Navbar -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#top">Home</a>
      <a class="navbar-item" href="#abstract">Abstract</a>
      <a class="navbar-item" href="#system">System</a>
      <a class="navbar-item" href="#results">Results</a>
      <a class="navbar-item" href="#bibtex">BibTeX</a>
    </div>
  </div>
</nav>

<!-- Hero -->
<section id="top" class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-2 publication-title">
        FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR
      </h1>

      <p class="is-size-5">Junzhe Wu<sup>1</sup>, Yufei Jia<sup>2</sup>, Yiyi Yan<sup>3</sup>, Zhixing Chen<sup>1</sup>, Tiao Tan<sup>1</sup>, Zifan Wang<sup>4</sup>, Guangyu Wang<sup>1</sup>, BoKui Chen<sup>1†</sup>, Guyue Zhou<sup>5†</sup></p>
      <p class="is-size-6"><sup>1</sup>Tsinghua Univ. (Shenzhen) · <sup>2</sup>Tsinghua Univ. (Beijing) · <sup>3</sup>DISCOVER Robotics · <sup>4</sup>HKUST (Guangzhou) · <sup>5</sup>AIR, Tsinghua Univ.</p>

      <div class="buttons is-centered" style="margin-top:10px;">
        <a href="static/pdf/paper.pdf" class="button is-dark is-rounded">Paper (PDF)</a>
        <a href="https://arxiv.org/abs/2509.17390" class="button is-dark is-rounded">arXiv</a>
        <a href="https://github.com/TATP-233/FGGS-LiDAR" class="button is-dark is-rounded">Code</a>
      </div>
    </div>
  </div>
</section>

<!-- Demo -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video class="demo" controls autoplay muted loop playsinline preload="metadata" poster="./static/images/teaser_01.png">
        <source src="https://raw.githubusercontent.com/xyys2003/test.github.io/main/static/videos/demo_show.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered" style="margin-top:12px;">
        End-to-end pipeline demo (3DGS → Mesh → LiDAR)
      </h2>
    </div>
  </div>
</section>

<!-- Abstract -->
<section id="abstract" class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        While <b>3D Gaussian Splatting (3DGS)</b> has revolutionized photorealistic rendering, its vast ecosystem of assets remains incompatible with high-performance LiDAR simulation, a critical tool for robotics and autonomous driving.
        We present <b>FGGS-LiDAR</b>, a framework that bridges this gap with a truly plug-and-play approach.
        Our method converts <i>any</i> pretrained 3DGS model into a high-fidelity, watertight mesh without requiring LiDAR-specific supervision or architectural alterations.
      </p>
      <p>
        This conversion is achieved through a general pipeline of volumetric discretization and <b>Truncated Signed Distance Field (TSDF)</b> extraction.
        We pair this with a highly optimized, GPU-accelerated ray-casting module that simulates LiDAR returns at over <b>500 FPS</b>.
        We validate our approach on indoor and outdoor scenes, demonstrating exceptional geometric fidelity.
        By enabling the direct reuse of 3DGS assets for geometrically accurate depth sensing, our framework extends their utility beyond visualization and unlocks new capabilities for scalable, multimodal simulation.
      </p>
    </div>
  </div>
</section>

<!-- ===== System (ordered blocks, no "Method" group) ===== -->
<section id="system" class="section">
  <div class="container is-max-desktop">

    <!-- 1. System Overview -->
    <div class="box">
      <h3 class="title is-5 has-text-centered">System Overview</h3>
      <img src="./static/images/teaser_01.png" alt="System Overview" class="figure">
      <p class="explain">
        FGGS-LiDAR integrates Gaussian-based scene representation, watertight mesh reconstruction, and GPU-parallel LiDAR simulation. 
        Pretrained 3DGS assets are discretized into occupancy volumes, fused into a narrow-band TSDF, and converted to meshes. 
        A BVH-accelerated ray-casting engine then performs first-hit queries at real-time rates, enabling physically grounded, scalable LiDAR sensing directly from general 3DGS content.
      </p>
    </div>

    <!-- 2. 3DGS Voxelization -->
    <div class="box">
      <h3 class="title is-5 has-text-centered">3DGS Voxelization</h3>
      <img src="./static/images/voxelization_01.png" alt="Voxelization" class="figure">
      <p class="explain">
        We convert continuous Gaussian fields into sparse occupancy grids via LBVH-accelerated accumulation. 
        Each Gaussian contributes probabilistically to local density, preserving thin structures and high-frequency geometry while keeping the memory footprint compact. 
        This forms the basis for robust TSDF reconstruction in the next stage.
      </p>
    </div>

    <!-- 3. Denoised → Mesh -->
    <div class="box">
      <h3 class="title is-5 has-text-centered">Denoised → Mesh</h3>
      <img src="./static/images/denoised_01.png" alt="Denoised Mesh" class="figure">
      <p class="explain">
        We perform narrow-band TSDF propagation and extract surfaces with Marching Cubes, followed by structure-preserving smoothing. 
        The resulting meshes are watertight and topologically consistent, eliminating local artifacts without shrinking geometry. 
        Such meshes are ideal for accurate, physically meaningful ray–triangle intersection in LiDAR simulation.
      </p>
    </div>

    <!-- 4. Scene Rendering (moved after Mesh) -->
    <div class="box">
      <h3 class="title is-5 has-text-centered">Scene Rendering</h3>
      <img src="./static/images/rendering_01.png" alt="Rendering" class="figure">
      <p class="explain">
        Mesh-based rendering retains the global structure and sharp boundaries of the original scenes while providing reliable normals and visibility for sensing. 
        Compared to splat-only rendering, the reconstructed geometry offers consistent surfaces and fewer blending artifacts, 
        ensuring high visual fidelity and compatibility with physically grounded LiDAR ray interactions.
      </p>
    </div>

    <!-- 5. Depth Limitations (rewritten with your content) -->
    <div class="box">
      <h3 class="title is-5 has-text-centered">Depth Limitations</h3>
      <img src="./static/images/depth_01.png" alt="Depth Limitations" class="figure">
      <p class="explain">
        <b>Imaging principle.</b> In 3DGS, “depth” is an opacity-weighted expectation along the camera ray— a view-dependent average rather than a true geometric intersection. 
        This leads to characteristic artifacts: edges and thin structures appear blurred or widened due to splat blending, 
        and underconstrained regions (back-facing or rarely observed surfaces, low-texture areas, glossy materials) produce dropouts or holes. 
        LiDAR instead reports first-return geometric distances, directly tied to scene geometry and free of averaging artifacts.
      </p>
      <p class="explain">
        <b>Computational efficiency.</b> Depth rendering in 3DGS accumulates over many anisotropic Gaussians per pixel; 
        its cost and memory grow with image resolution and footprint, making high-res rendering expensive. 
        Our simulator performs BVH-accelerated ray–triangle intersections whose cost mainly scales with beam and triangle counts. 
        Independent rays enable highly efficient GPU parallelization and stable performance across scenes.
      </p>
    </div>

  </div>
</section>

<!-- Results -->
<section id="results" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Results</h2>

    <div class="box">
      <h3 class="title is-5 has-text-centered">LiDAR FPS vs Triangle Count</h3>
      <img src="./static/images/lidar_fps_01.png" alt="LiDAR FPS" class="figure">
      <p class="explain">
        <b>Frame rate.</b> Owing to the BVH acceleration structure, across all evaluated 3DGS scenes (up to ~6M Gaussian primitives) we observe no systematic degradation of simulation frame rate with increasing primitive count. 
        Within this scale, performance is effectively decoupled from raw cardinality. 
        Instead, traversal efficiency is primarily governed by spatial distribution characteristics—such as clustering patterns, local density heterogeneity, and occlusion layering—rather than absolute counts. 
        Our system delivers <i>far beyond real-time performance</i> and ranks among the fastest in peer comparisons, highlighting the efficiency of the proposed pipeline.
      </p>
    </div>

    <div class="box">
      <h3 class="title is-5 has-text-centered">LiDAR Throughput vs Triangle Count</h3>
      <img src="./static/images/lidar_throughput_01.png" alt="LiDAR Throughput" class="figure">
      <p class="explain">
        <b>Throughput.</b> Point throughput grows with sensor density and remains high across mesh complexities. 
        Despite lower FPS, denser sensors (e.g., OS128, VLP32) achieve significantly higher throughput, exceeding 1×10<sup>8</sup> points/s on lightweight meshes and sustaining &gt;7.5×10<sup>7</sup> points/s even at multi-million triangle scales. 
        This demonstrates that our method fully exploits BVH-accelerated parallelism and maintains high utilization across diverse LiDAR types.
      </p>
    </div>
  </div>
</section>

<!-- BibTeX -->
<section id="bibtex" class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<pre><code>@article{FGGS_LiDAR_2025,
  title   = {FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR},
  author  = {Wu, Junzhe and Jia, Yufei and Yan, Yiyi and Chen, Zhixing and Tan, Tiao and Wang, Zifan and Wang, Guangyu and Chen, BoKui and Zhou, Guyue},
  journal = {arXiv preprint arXiv:2509.17390},
  year    = {2025}
}</code></pre>
  </div>
</section>


</body>
</html>
